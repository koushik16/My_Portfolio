<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Koushik Reddy Parukola</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <!-- <h1>Koushik Reddy Parukola</h1> -->
        <header>
          <h1>Koushik Reddy Parukola</h1>
          <img src="unnamed6.jpg" alt="Koushik Reddy, Parukola" style="width: 300px; height: auto;">
          
          <div style="margin-top: 10px; line-height: 0.4;">
            <p><strong>Contact:</strong> <a href="mailto:koparu@iu.edu">koparu [at] iu.edu</a><br>
            <!-- <p><strong>Contact:</strong> koparu[at]iu.edu</p> -->
            <p><strong>GitHub:</strong> <a href="https://github.com/koushik16">koushik16</a></p>
            <p><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/koushik-reddy-parukola">Koushik Reddy Parukola</a></p>
            <!-- <p><strong>Twitter:</strong> <a href="https://twitter.com/koushik16">@koushik16</a></p> -->
            <p><a href="resume v1.3.pdf" download>Download CV</a> | <a href="transcript.pdf" download>Download Transcript</a></p>

          </div>
          <!-- <p>This page is part of <a href="index.html">Koushik Reddy Parukola's portfolio</a></p> -->
        <!-- <footer> -->
          <div class="footer-content">
          <footer style="text-align: left; margin-top: 20px;">
          <p>This project is maintained by <a href="http://github.com/koushik16">Koushik</a></p>
          <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
        </footer>
      </div>
      </header>

        <!-- <p class="view"><a href="http://github.com/koushik16/my_portfolio">View the Project on GitHub <small>koushik16/my_portfolio</small></a></p> -->
        <!-- <ul> -->
          <!-- <li><a href="https://github.com/orderedlist/minimal/zipball/master">Download <strong>ZIP File</strong></a></li> -->
          <!-- <li><a href="https://github.com/orderedlist/minimal/tarball/master">Download <strong>TAR Ball</strong></a></li> -->
          <!-- <li><a href="http://github.com/orderedlist/minimal">Fork On <strong>GitHub</strong></a></li> -->
        <!-- </ul> -->
      </header>
      <!-- <section> -->
        <!-- <p><em>View the <a href="http://github.github.com/github-flavored-markdown/sample_content.html">source of this content</a>.</em></p> -->
      <!-- </section> -->

      <!-- <section id="about-me">
        <h2>About Me</h2>
        <p>
          I'm Koushik Reddy Parukola, a PhD candidate with a passion for pushing the boundaries of <strong>Quantum AI</strong> and <strong>NLP</strong>.
          With a Master’s in Data Science from Indiana University, I am currently working in the <a href="https://damir.cavar.me/" target="_blank">NLP lab at Indiana University</a> as a Research Assistant, under the guidance of, <a href="https://damir.cavar.me/" target="_blank">Prof. Damir Cavar</a>. My work focuses on developing advanced natural language processing models and techniques.
        </p>
        <p>
          My research interests lie in the intersection of <strong>quantum computing, natural language processing (NLP), and deep learning</strong>, with a focus on word embeddings, Knowledgr graphs, LLM applications.
          Over the years, I’ve developed expertise in various machine learning techniques, from <strong>classical models</strong> like neural networks to <strong>quantum machine learning</strong> using Qiskit and PennyLane.
        </p>
      </section> -->
<!-- 
      <section id="about" class="about">
        <div class="container">
          <h2>About Me</h2>
          <p>
            I'm <strong>Koushik Reddy Parukola</strong>, an <strong>AI/ML Engineer</strong> with a passion for building intelligent systems that extract insights from unstructured data and enhance decision-making through automation.
          </p>
          <p>
            My work spans a wide range of applications — from <strong>LLM fine-tuning</strong> and <strong>document intelligence</strong> to <strong>quantum NLP research</strong> and <strong>agentic AI workflows</strong>. I specialize in developing scalable AI solutions, optimizing transformer-based models, and integrating <strong>retrieval-augmented generation (RAG)</strong> pipelines in real-world scenarios.
          </p>
          <p>
            Currently, I’m building AI-driven systems for insurance, fintech, and biomedical domains, and actively contributing to research on <strong>quantum state representations of language</strong> and <strong>lightweight adaptation of language models</strong>.
          </p>
          <p>
            I’ve published and presented my work at conferences like <strong>IEEE ICASSP</strong> and <strong>Midwest NLP Days</strong>, and I co-organize the <strong>qnlp.ai</strong> conference hosted by Indiana University.
          </p>
        </div>
      </section> -->
      <section id="about" class="about">
        <div class="container">
          <h2>About Me</h2>
      
          <p>
            I'm <strong>Koushik Reddy Parukola</strong>, an <strong>AI/ML Engineer</strong> passionate about building intelligent systems that extract insights from unstructured data and support real-time decision-making through automation.
          </p>
      
          <p>
            My work spans a wide range of applications, including <strong>LLM fine-tuning</strong>, <strong>document intelligence</strong>, <strong>retrieval-augmented generation (RAG)</strong>, and <strong>quantum NLP research</strong>. I specialize in developing scalable workflows that combine deep learning, transformer-based models, and reasoning pipelines with structured outputs.
          </p>
      
          <p>
            I’m currently building AI-driven solutions for domains such as insurance, fintech, and healthcare. My research also explores <strong>quantum state representations of language</strong> and <strong>lightweight model adaptation</strong> using techniques like LoRA and quantization.
          </p>
      
          <p>
            I've presented my work at conferences like <strong>IEEE ICASSP</strong> and <strong>Midwest NLP Days</strong>, and I co-organize the <a href="https://qnlp.ai" target="_blank"><strong>qnlp.ai</strong></a> conference hosted by Indiana University in collaboration with ACM SIGAI.
          </p>
        </div>
      </section>
      
      

      <!-- <section id="research">
        <h2>Research</h2>
        <p>
          My research focuses on the intersection of <strong>classical-quantum computing, artificial intelligence (AI), deep learning, NLP and large language models (LLMs)</strong>. 
          I explore innovative applications of quantum computing in natural language processing and AI, developing models that push the boundaries of current deep learning techniques.
        </p>
        <p>
          Key areas of interest include:
          <ul>
            <li>Quantum data encoding and circuit optimization for machine learning applications</li>
            <li>Exploring the contextual and semantic understanding within large language models</li>
            <li>Developing hybrid classical-quantum AI models for advanced problem-solving</li>
            <li>Optimizd RAG/AI pipelined for Efficeint computing and proccessingdata in sensetice sectors like medical and finance</li>
          </ul>
        </p>
        <p>The <a href="https://nlp-lab.org/quantumnlp/" target="_blank"> ongoing research focus </a> is on advancing quantum computing techniques and applying them to enhance Quantum NLP and AI. By exploring the Quantum Fourier Transform (QFT), I aim to improve frequency analysis within quantum states, enabling more efficient data representation for complex language processing tasks. Additionally, my work on introducing non-linearity in quantum circuits addresses the limitations of linear transformations, offering more expressive power and flexibility in quantum models, which is crucial for nuanced language and AI applications. Through Hamiltonian optimization, I am developing methods to solve intricate problem landscapes with greater efficiency, which is essential for scaling up Quantum AI models. Together, these efforts support building more robust and scalable Quantum NLP and AI frameworks, with applications that extend into practical domains such as drug discovery through optimized Retrieval-Augmented Generation (RAG) pipelines.</p>
        <p>
          <a href="research.html">Learn more about my research &rarr;</a>
        </p>
      </section> -->
      <section id="research" class="research">
        <div class="container">
          <h2>Research</h2>
          <p>
            My research at the NLP Lab, Indiana University, explores how AI systems interpret, encode, and extract semantic knowledge from unstructured data. I focus on enhancing the performance and interpretability of large language models (LLMs) through token embedding analysis, transformer diagnostics, and retrieval-based agentic frameworks.
          </p>
      
          <h3>Key areas of focus include:</h3>
          <ul>
            <li>Analyzing embedding spaces (using PCA, t-SNE, Fisher’s Discriminant) to detect semantic drift across tokens</li>
            <li>Investigating how transformers ground syntax and semantics via attention mechanisms and cross-attention flows</li>
            <li>Studying the behavior of LLMs under LoRA fine-tuning and quantization in biomedical domains</li>
            <li>Developing parsing pipelines using NERs, dependency trees, and triplet extraction for knowledge graph generation</li>
            <li>Building RAG-based AI agents for automated information extraction and knowledge synthesis</li>
          </ul>
      
          <p>
            I also explore the integration of quantum computing with NLP. My quantum work focuses on data encoding strategies, model optimization, and interpreting quantum-classical hybrid representations.
          </p>
      
          <h3>Quantum NLP & Quantum ML research includes:</h3>
          <ul>
            <li>Amplitude encoding of classical embeddings and preparation of unitary matrices</li>
            <li>Hamiltonian generation using eigen decomposition from unitary evolution</li>
            <li>Circuit design and optimization using tools like Pennylane and Qiskit</li>
            <li>Quantum circuit transpilation and simulation for depth and gate efficiency</li>
            <li>Building foundational components for Quantum NLP and Quantum RAG frameworks</li>
          </ul>
      
          <p>
            I'm also part of the organizing committee for the <a href="https://qnlp.ai" target="_blank"><strong>qnlp.ai</strong></a> conference, hosted by Indiana University in collaboration with ACM SIGAI, where I contribute to advancing discussions at the intersection of NLP and quantum computing.
          </p>
          <p><a href="research.html">View my Research &rarr;</a></p>
        </div>
      </section>
      
      
        
        <section id="projects">
          <h2>Projects</h2>
          <p>I have worked on a variety of projects spanning quantum computing, NLP, bioinformatics, and machine learning. Here are a few highlights:</p>
          
          <ul>
            <li><strong>AI/ML:</strong> Developed end-to-end AI systems for intelligent document understanding, real-time decision-making, and predictive analytics. Projects include language model fine-tuning for semantic tasks, document parsing pipelines for information extraction, graph-based models for biomedical prediction, and time-series models for behavioral forecasting. Emphasis on scalable architecture, domain adaptation, and interpretable model design using LLMs, RAG, GNNs, and CNNs.</li>

            <li><strong>Quantum Projects:</strong> My quantum computing work explores the intersection of machine learning and quantum models, including Quantum Neural Networks (QNNs) and Variational Quantum Circuits (VQC), focusing on advanced data processing techniques.</li>
            
            <li><strong>Other Projects:</strong> Additional projects span diverse applications in ML, quantum experiments, and automation, addressing unique challenges with innovative solutions.</li>
          </ul>
          
          <p><a href="projects.html">View all projects &rarr;</a></p>
        </section>
        
      

        <section id="publications">
          <h2>Publications & Talks</h2>
        
          <!-- Publication 1 -->
          <p>
            <a href="icassp.pdf" target="_blank">Text Similarity Using Classical Word Embeddings in Quantum Systems</a> 
            IEEE International Conferance on Acoustics, Speech, and Signal Processing 2025, India<br>
            <em>Damir Cavar, Koushik Reddy Parukola.</em>
          </p>

          <p>
            <a href="https://nlp.nd.edu/msld25/" target="_blank">Word Embeddings in Quantum NLP Systems</a> 
            Midwest Speech and Language Days 2025, University of Notre Dame, Indiana.<br>
            <em>Damir Cavar, Koushik Reddy Parukola, Shane Sparks.</em>
          </p>
        
          <!-- Publication 2 -->
          <p>
            <a href="https://www.scribd.com/document/512777646/Traffic-Sign-Classification" target="_blank">Sign Recogniton System</a> 
            Published in International Journal of Innovative Science and Research Technology (IJISET), Vol. 6, Issue. 6, 2021.<br>
            <em>Koushik Reddy Parukola</em>
          </p>
        
          <!-- Publication 3 -->
          <p>
            <a href="https://luddy.indiana.edu/index.html" target="_blank">NLP-Lab poster (2024) - Quantum Natural Language processing and Machine Learning</a> 
            Luddy-Crane Summit on March 29, 2024 at Indiana University Bloomington., 2022.<br>
            <em>NLP-Lab Team</em>
          </p>
            
        <!-- <p><a href="publications.html">View all publications & Abstracts &rarr;</a></p> -->
      </section>


      <section id="certifications">
        <h2>Certifications & organizations</h2>
        <ul>
          <li>Organizing Comittee - Quantum AI and NLP Conferance 2025, Indiana University.</li>
          <li>Student Member IEEE, ACM and ACM-SIGAI</li>
          <li>Vice President - App Development Club @ NHCE 2019-2021</li>
          <li>Certified AWS AI Practitioner</li>
          <li>Quantum challenge 2024 - IBM Quantum</li>
          <li>Qiskit Global summer school - IBM quantum</li>
          <li>Advanced NLP with Deep Learning and Transformers - Udemy</li>
          <li>Azure Fundamentals - Microsoft</li>
          <!-- Add other certifications here -->
        </ul>
      </section>
      


      <section id="teaching">
        <h2>Teaching</h2>
        <p>
          I served as an Associate Instructor for the <strong>Game Programming</strong> course. In this role, I guided students through hands-on projects and advanced programming concepts, helping them develop practical skills in AI and ML for Game development.
        </p>
        <ul>
          <li>Developed lesson plans and led interactive sessions covering ML frameworks like A*, Monte Carlo Tree Search and other tools like Unity Engine.</li>
          <li>AI for Interactive NPC Development: Applied Generative AI to create adaptive Non-Player Characters (NPCs) with responsive, AI-driven dialogue, enhancing interactivity and immersion in game environments.</li>
          <li>Provided one-on-one mentorship and support for students’ programming projects.</li>
          <li>Received positive feedback for clear explanations and fostering an engaging learning environment.</li>
        </ul>
      </section>
      



      
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
